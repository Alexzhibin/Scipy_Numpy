{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.1 Data Modeling and Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Curve_fit. Find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a function to model and create data\n",
    "def func(x,a,b):\n",
    "    return a*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating clean data\n",
    "x = np.linspace(0,10,100)\n",
    "y = func(x,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to the data\n",
    "yn = y+0.9*np.random.normal(size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Executing curve_fit on noisy data\n",
    "popt,pcov = curve_fit(func,x,yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#popt returns the best fir values for parameters of the \n",
    "#given model(func)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99722223,  2.13209517])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###check the quality of the fit with pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a function to model and create data\n",
    "def func(x,a,b,c):\n",
    "    return a*np.exp(-(x-b)**2/(2*c**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating clean data\n",
    "x = np.linspace(0,10,100)\n",
    "y = func(x,1,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to the data \n",
    "yn = y+0.2*np.random.normal(size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Executing curve_fit on noisy data\n",
    "popt,pcov = curve_fit(func,x,yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02570894,  4.99078855, -1.92682167])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#popt returns the best-fit values for parameters of the given model(func)\n",
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Two-Gaussian model\n",
    "def func(x,a0,b0,c0,a1,b1,c1):\n",
    "    return a0*np.exp(-(x-b0)**2/(2*c0**2))\\\n",
    "        +a1*np.exp(-(x-b1)**2/(2*c1**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating clean data\n",
    "x = np.linspace(0,20,200)\n",
    "y = func(x,1,3,1,-2,15,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to the data \n",
    "yn = y+0.2*np.random.normal(size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since we are fitting a more complex function, \n",
    "#providing guesses for the fitting will lead to \n",
    "#better results\n",
    "guesses=[1,3,1,1,15,1]\n",
    "#Executing curve_fit on noisy data\n",
    "popt,prov = curve_fit(func,x,yn,p0=guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.01427407,   2.88595811,   1.00665975,  -1.95092546,\n",
       "        15.03782582,   0.50428664])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Solutions to Functions\n",
    "#scipy.optimize.fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = lambda x:x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = fsolve(line,-2)\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding the intersection points between two equations is nearly as simple\n",
    "from scipy.optimize import fsolve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining function to simplify intersection solution\n",
    "def findIntersection(func1,func2,x0):\n",
    "    return fsolve(lambda x:func1(x)-func2(x),x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining functions that will intersect\n",
    "funky = lambda x:np.cos(x/5)*np.sin(x/2)\n",
    "line = lambda x:0.01*x-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining range and getting solutions on intersection points\n",
    "x = np.linspace(0,45,10000)\n",
    "result = findIntersection(funky,line,[15,20,30,35,40,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 13.40773078,  18.11366128,  31.78330863,  37.0799992 ,\n",
      "        39.84837786,  43.8258775 ]), array([-0.36592269, -0.31886339, -0.18216691, -0.12920001, -0.10151622,\n",
      "       -0.06174122]))\n"
     ]
    }
   ],
   "source": [
    "#Printing out results for x and y\n",
    "print(result,line(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.2 Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up fake data\n",
    "x = np.linspace(0,10*np.pi,20)\n",
    "y = np.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Interpolating data\n",
    "f1 = interp1d(x,y,kind='linear')\n",
    "fq = interp1d(x,y,kind='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x.min and x.max are used to make sure we do not\n",
    "#go beyond the boundaries of the data for the interpolation\n",
    "xint = np.linspace(x.min(),x.max(),1000)\n",
    "yint1 = f1(xint)\n",
    "yintq = fq(xint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###3.2.2 Interpolate noisy data with univariate example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up fake data with artificial noise\n",
    "sample = 30\n",
    "x = np.linspace(1,10*np.pi,sample)\n",
    "y = np.cos(x)+np.log10(x)+np.random.randn(sample)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Interpolating the data\n",
    "f = UnivariateSpline(x,y,s=1) \n",
    "#the option s is the smppthing factor, which should be used when fitting data with noise\n",
    "#if instead s =0, then the interpolation will go through all points while ignoring all noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x.min and x.max are used to make sure we do not \n",
    "#go beyond the boundaries of the data for the interpolation.\n",
    "xint = np.linspace(x.min(),x.max(),1000)\n",
    "yint = f(xint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###3.2.3 Interpolate noisy data with multivariate example\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining a function \n",
    "ripple = lambda x,y:np.sqrt(x**2+y**2)+np.sin(x**2+y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating gridded data. The complex number defines\n",
    "#how many steps the grid data should have. Without the \n",
    "#complex number mgrid would only create a grid data structure\n",
    "#with 5 steps.\n",
    "grid_x,grid_y = np.mgrid[0:5:1000j,0:5:1000j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating sample that interpolation function will see\n",
    "xy = np.random.rand(1000,2)\n",
    "sample = ripple(xy[:,0]*5,xy[:,1]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Interpolating data with a cubic\n",
    "grid_z0 = griddata(xy*5,sample,(grid_x,grid_y),method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "import numpy as np\n",
    "from scipy.interpolate import SmoothBivariateSpline as SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definig a function\n",
    "ripple = lambda x,y:np.sqrt(x**2+y**2)+np.sin(x**2+y**2)\n",
    "x,y = xy[:,0],xy[:,1]\n",
    "sample = ripple(xy[:,0]*5,xy[:,1]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AlexCen1/anaconda/lib/python2.7/site-packages/scipy/interpolate/fitpack2.py:931: UserWarning: ier=45589\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#Interpolating data \n",
    "fit = SBS(x*5,y*5,sample,s=0.01,kx=4,ky=4)\n",
    "interp = fit(np.linspace(0,5,1000),np.linspace(0,5,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.3.1 Analytic Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining function to integrate\n",
    "func = lambda x:np.cos(np.exp(x))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.296467785724373, 1.397797186265988e-09)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Integrating function with upper and lower\n",
    "#limits of 0 and 3, respectively \n",
    "solution = quad(func,0,3)\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The first element is the desired value\n",
    "#and the second is the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##3.3.2 Numerical Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad,trapz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up fake data\n",
    "x = np.sort(np.random.randn(150)*4+4).clip(0,5)\n",
    "func = lambda x: np.sin(x)*np.cos(x**2)+1\n",
    "y = func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Integrating function with upper and lower\n",
    "#Limits of 0 and 5, respectively\n",
    "fsolution = quad(func,0,5)\n",
    "dsolution = trapz(y,x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsolution = 5.10034506754\n",
      "dsolution = 5.19752966411\n",
      "The difference is0.0971845965696\n"
     ]
    }
   ],
   "source": [
    "print('fsolution = '+str(fsolution[0]))\n",
    "print('dsolution = '+str(dsolution))\n",
    "print('The difference is'+str(np.abs(fsolution[0]-dsolution)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constructing a random array with 1000 elements\n",
    "x = np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating several of the built-in methods\n",
    "#that numpy.array has\n",
    "mean = x.mean()\n",
    "std = x.std()\n",
    "var = x.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4.1 Continuous and Discrete distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up the sample range\n",
    "x = np.linspace(-5,5,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here set up the parameters for the normal distribution,\n",
    "#where loc is the mean and scale is the standard deviation.\n",
    "dist = norm(loc=0,scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Retrieving norm's PDF and CDF\n",
    "pdf = dist.pdf(x)\n",
    "cdf = dist.cdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we draw out 500 random values from the norm.\n",
    "sample = dist.rvs(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "from scipy.stats import geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here set up the parameters fro the meometric distribution\n",
    "p = 0.5\n",
    "dist = geom(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up the sample range\n",
    "x = np.linspace(0,5,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieving geom's PMF and CDF \n",
    "pmf = dist.pmf(x)\n",
    "cdf = dist.cdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we draw out 500 random values\n",
    "sample = dist.rvs(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating a normal distribution sample\n",
    "#with 100 elements\n",
    "sample = np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normaltest output\n",
      "Z-score=0.372630023713\n",
      "P-value=0.830012090146\n"
     ]
    }
   ],
   "source": [
    "#Normaltest tests the null hypothesis.\n",
    "out = stats.normaltest(sample)\n",
    "print('normaltest output')\n",
    "print('Z-score='+str(out[0]))\n",
    "print('P-value='+str(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kstest output for the Normal distribution\n",
      "D= 0.108403416128\n",
      "P-value=0.177198754279\n"
     ]
    }
   ],
   "source": [
    "#kstest is the Kolmogorov-Smirnov test for goodness of fit.\n",
    "#Here its sample is being tested against the normal distribution.\n",
    "#D is the KS statistic and the closer it is to 0 the better.\n",
    "out = stats.kstest(sample,'norm')\n",
    "print('\\nkstest output for the Normal distribution')\n",
    "print('D= '+str(out[0]))\n",
    "print('P-value='+str(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kstest output for the Wald distribution\n",
      "D=0.469992263215\n",
      "P-value=0.0\n"
     ]
    }
   ],
   "source": [
    "#Similarly, this can be easily tested against other distributions,\n",
    "#like the Wald distribution.\n",
    "out = stats.kstest(sample,'wald')\n",
    "print('\\nkstest output for the Wald distribution')\n",
    "print('D='+str(out[0]))\n",
    "print('P-value='+str(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating a normal distribution sample\n",
    "#with 100 elements\n",
    "sample = np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic mean=0.249416392778\n"
     ]
    }
   ],
   "source": [
    "#The harmonic mean:Sample values have to \n",
    "#be greater than 0.\n",
    "out = stats.hmean(sample[sample>0])\n",
    "print('Harmonic mean='+str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trimmed mean=-0.00497096341963\n"
     ]
    }
   ],
   "source": [
    "#The mean,where values below -1 and above 1 are\n",
    "#removed for the mean calculation\n",
    "out = stats.tmean(sample,limits=(-1,1))\n",
    "print('\\nTrimmed mean='+str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skewness=-0.209745338686\n"
     ]
    }
   ],
   "source": [
    "#Calculating the skewness of the sample\n",
    "out = stats.skew(sample)\n",
    "print('\\nSkewness='+str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size=100\n",
      "Min=-2.56237406016\n",
      "Max=2.04908323788\n",
      "Mean=-0.0496547319821\n",
      "Variance=1.08223066532\n",
      "Skewness=-0.209745338686\n",
      "Kurtosis=-0.409599342968\n"
     ]
    }
   ],
   "source": [
    "#Additionally, there is a handy summary function called\n",
    "#describe, which gives a quick look at the data.\n",
    "out = stats.describe(sample)\n",
    "print('\\nSize='+str(out[0]))\n",
    "print('Min='+str(out[1][0]))\n",
    "print('Max='+str(out[1][1]))\n",
    "print('Mean='+str(out[2]))\n",
    "print('Variance='+str(out[3]))\n",
    "print('Skewness='+str(out[4]))\n",
    "print('Kurtosis='+str(out[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Spatial and Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3.5.1 Vector Quantization\n",
    "import numpy as np\n",
    "from scipy.cluster import vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating data\n",
    "c1 = np.random.randn(100,2)+5\n",
    "c2 = np.random.randn(30,2)-5\n",
    "c3 = np.random.randn(50,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pooling all the data into one 180x2 array\n",
    "data = np.vstack([c1,c2,c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating the cluster centroids and variance\n",
    "#from kmeans\n",
    "centroids,variance = vq.kmeans(data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The identified variable contains the information\n",
    "#we need to separate the points in clusters\n",
    "#based on the vq function.\n",
    "identified,distance = vq.vq(data,centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieving coordinates for points in each vq\n",
    "#identified core\n",
    "vqc1 = data[identified ==0] #the first cluster\n",
    "vqc2 = data[identified ==1] #the second cluster\n",
    "vqc3 = data[identified ==2] #the third cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.2 Hierarchical Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "import scipy.cluster.hierarchy as hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a cluster of clusters function\n",
    "def clusters(number=20,cnumber=5,csize=10):\n",
    "    #Note that the way the clusters are postioned is Gaussian randomness.\n",
    "    rnum = np.random.rand(cnumber,2)\n",
    "    rn = rnum[:,0]*number\n",
    "    rn = rn.astype(int)\n",
    "    rn[np.where(rn<5)]=5\n",
    "    rn[np.where(rn>number/2.)] = round(number/2.,0)\n",
    "    ra = rnum[:,1]*2.9\n",
    "    ra[np.where(ra<1.5)]=1.5\n",
    "    cls = np.random.randn(number,3)*csize\n",
    "    #Random multipliers for central point of cluster\n",
    "    rxyz = np.random.randn(cnumber-1,3)\n",
    "    for i in xrange(cnumber-1):\n",
    "        tmp = np.random.randn(rn[i+1],3)\n",
    "        x = tmp[:,0]+(rxyz[i,0]*csize)\n",
    "        y = tmp[:,1]+(rxyz[i,1]*csize)\n",
    "        z = tmp[:,2]+(rxyz[i,2]*csize)\n",
    "        tmp = np.column_stack([x,y,z])\n",
    "        cls = np.vstack([cls,tmp])\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate a cluster of clusters and distance matrix.\n",
    "cls = clusters()\n",
    "D = pdist(cls[:,0:2])\n",
    "D = squareform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute and plot first dendrogram.\n",
    "fig = mpl.figure(figsize=(8,8))\n",
    "ax1 = fig.add_axes([0.09,0.1,0.2,0.6])\n",
    "Y1 = hy.linkage(D,method='complete')\n",
    "cutoff = 0.3*np.max(Y1[:,2])\n",
    "Z1 = hy.dendrogram(Y1,orientation='right',color_threshold=cutoff)\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute and plot second dendrogram.\n",
    "ax2 = fig.add_axes([0.3,0.71,0.6,0.2])\n",
    "Y2 = hy.linkage(D,method='average')\n",
    "cutoff = 0.3*np.max(Y2[:,2])\n",
    "Z2 = hy.dendrogram(Y2,color_threshold=cutoff)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot distance matrix.\n",
    "ax3 = fig.add_axes([0.3,0.1,0.6,0.6])\n",
    "idx1 = Z1['leaves']\n",
    "idx2 = Z2['leaves']\n",
    "D = D[idx1,:]\n",
    "D = D[:,idx2]\n",
    "ax3.matshow(D,aspect='auto',origin='lower',cmap=mpl.cm.YlGnBu)\n",
    "ax3.xaxis.set_visible(False)\n",
    "ax3.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot colorbar\n",
    "fig.savefig('cluster_hy_f01.pdf',bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distinguish the structures from one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same imports and cluster function from the previous example\n",
    "#follow through here.\n",
    "#Here we define a function to collect the coordinates of \n",
    "#each point of the different clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group(data,index):\n",
    "    number = np.unique(index)\n",
    "    groups = []\n",
    "    for i in number:\n",
    "        groups.append(data[index==i])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a cluster of clusters \n",
    "cls = clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating the linkage matrix\n",
    "Y = hy.linkage(cls[:,0:2],method='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here we use the fcluster function to pull out a \n",
    "#collection of flat clusters from the hierarchical\n",
    "#data structure.Note that we are using the same cutoff value as \n",
    "#in the previous example for the dendrogram\n",
    "#using the 'complet' method.\n",
    "cutoff = 0.3*np.max(Y[:,2])\n",
    "index = hy.fcluster(Y,cutoff,'distance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using the group function, we group points into their\n",
    "#respective clusters\n",
    "groups = group(cls,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting clusters\n",
    "fig = mpl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111)\n",
    "colors = ['r','c','b','g','orange','k','y','gray']\n",
    "for i,g in enumerate(groups):\n",
    "    i = np.mod(i,len(colors))\n",
    "    ax.scatter(g[:,0],g[:,1],c=colors[i],edgecolor='none',s=50)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig('cluster_hy_f02.pdf',bbox='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3.6 Signal and Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread,imsave\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the list of files in the directory \n",
    "files = glob('space/*.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Opening up the first image for loop\n",
    "for i in xrange(1,len(files)):\n",
    "    print i \n",
    "    im1 += imread(files[i]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-db5c378dadaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Saving img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stacked_image.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'im1' is not defined"
     ]
    }
   ],
   "source": [
    "#Saving img\n",
    "imsave('stacked_image.jpg',im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread,imsave\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function allows us to place in the \n",
    "#brightest pixels per x and y position between \n",
    "#two images. It is similar to PIL's \n",
    "#ImageChop.Lighter function.\n",
    "def chop_lighter(image1,image2):\n",
    "    s1 = np.sum(image1,axis=2)\n",
    "    s2 = np.sum(image2,axis=2)\n",
    "    index = s1<s2\n",
    "    image1[index,0]=image2[index,0]\n",
    "    image1[index,1]=image2[index,1]\n",
    "    image1[index,2]=image2[index,2]\n",
    "    return image1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the list of files in the direactory \n",
    "files = glob('space/*.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b6c8cf384892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Opening up the first image for looping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Opening up the first image for looping \n",
    "im1 = imread(files[0]).astype(np.float32)\n",
    "im2 = np.copy(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Starting loop\n",
    "for i in xrange(1,len(files)):\n",
    "    print i \n",
    "    im = imread(files[i]).astype(np.float32)\n",
    "    #same before \n",
    "    im1 += im\n",
    "    #im2 shows star trails better\n",
    "    im2 = chop_lighter(im2,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-40729f5c89f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Saving image with slight tweaking on the combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#of the two images to show star trails with the co-added images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stack_image.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'im1' is not defined"
     ]
    }
   ],
   "source": [
    "#Saving image with slight tweaking on the combination \n",
    "#of the two images to show star trails with the co-added images.\n",
    "imsave('stack_image.jpg',im1/im1.max()+im2/im2.max()*0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import eigh\n",
    "import scipy.sparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3000\n",
    "#Creating a random sparse matrix \n",
    "m = scipy.sparse.rand(N,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating an array clone of it\n",
    "a = m.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numpy array data size:72000000bytes\n",
      "The sparse matrix data size:720000bytes\n"
     ]
    }
   ],
   "source": [
    "print('The numpy array data size:'+str(a.nbytes)+'bytes')\n",
    "print('The sparse matrix data size:'+str(m.data.nbytes)+'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Non-sparse\n",
    "to = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-sparse operation takes72.48seconds\n"
     ]
    }
   ],
   "source": [
    "res1 = eigh(a)\n",
    "dt = str(np.round(time.time()-to,3))+'seconds'\n",
    "print('Non-sparse operation takes'+dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse operation takes0.055seconds\n"
     ]
    }
   ],
   "source": [
    "#Sparse\n",
    "to = time.time()\n",
    "res2 = eigsh(m)\n",
    "dt = str(np.round(time.time()-to,3))+'seconds'\n",
    "print('Sparse operation takes'+dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
